{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from scipy import interp\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize, LabelBinarizer\n",
    "from sklearn.metrics import r2_score, f1_score, accuracy_score, roc_auc_score, roc_curve, auc, precision_score, recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import catboost as cb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корректируем датасет:  \n",
    "1) корректировка используемого в модели значения капитализации и разницы логарифмов между раундами  \n",
    "2) исключение раундов \"без ответа\"  \n",
    "3) приведение дат к нужному формату"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan = [np.nan]\n",
    "default_exit_value = 1 #\"капитализация\" мертвой компании в долларах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funding_round_uuid</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_uuid</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>announced_on</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>post_money_valuation_usd</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>exit_type</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>money_raised_usd</th>\n",
       "      <th>time_from_2009</th>\n",
       "      <th>time_from_start</th>\n",
       "      <th>time_from_previous</th>\n",
       "      <th>top_investor</th>\n",
       "      <th>other_investor</th>\n",
       "      <th>top_investor_count</th>\n",
       "      <th>other_investor_count</th>\n",
       "      <th>top_investor_sum</th>\n",
       "      <th>other_investor_sum</th>\n",
       "      <th>top_investor_rounds</th>\n",
       "      <th>other_investor_rounds</th>\n",
       "      <th>total_count</th>\n",
       "      <th>count_per_round</th>\n",
       "      <th>from_top5_count</th>\n",
       "      <th>PHD_count</th>\n",
       "      <th>Master_count</th>\n",
       "      <th>MBA_count</th>\n",
       "      <th>exp_months_min</th>\n",
       "      <th>exp_months_max</th>\n",
       "      <th>exp_months_mean</th>\n",
       "      <th>exp_months_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>778db45f-e9d1-3f73-86f4-ae4cc79c48ff</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>seed</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>365.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>---</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135.0335735846732</td>\n",
       "      <td>199.03488778003654</td>\n",
       "      <td>167.03423068235486</td>\n",
       "      <td>45.25576327239227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fc2c2560-8bb0-90d1-b048-ee9cfc3f301d</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_a</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>678.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.32347686810817</td>\n",
       "      <td>209.31846649828537</td>\n",
       "      <td>135.9863652231052</td>\n",
       "      <td>78.4149659700011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d863a1b9-dda0-284e-3258-fa43a20d305c</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_b</td>\n",
       "      <td>2011-05-02</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>851.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.00236144479354</td>\n",
       "      <td>106.25269512721</td>\n",
       "      <td>95.48239059035497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4c9cb685-ec9a-92ed-64c0-062040d9573e</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_unknown</td>\n",
       "      <td>2011-08-24</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>965.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.7478182303538</td>\n",
       "      <td>109.06178771638022</td>\n",
       "      <td>96.8798428111566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1006ef75-d2f2-bac4-5737-dae2075cf616</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2011-11-04</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.1133698843919</td>\n",
       "      <td>110.83595145690877</td>\n",
       "      <td>97.7706351449893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>80f5449a-2b38-f3eb-dc4f-d5b581e636ec</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_unknown</td>\n",
       "      <td>2010-12-14</td>\n",
       "      <td>1195972.0</td>\n",
       "      <td>---</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>712.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>---</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.45639540852994</td>\n",
       "      <td>140.553194110762</td>\n",
       "      <td>176.5474614109795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>e79c29e1-b5a7-db70-014d-36c2ba16338b</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_unknown</td>\n",
       "      <td>2010-12-20</td>\n",
       "      <td>792000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.6535247130331</td>\n",
       "      <td>140.6517587630136</td>\n",
       "      <td>176.64163261454254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>2067db69-a274-7914-0207-5fb1af6cc7ca</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2012-10-23</td>\n",
       "      <td>46000000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>448.7648617014723</td>\n",
       "      <td>151.7074272572332</td>\n",
       "      <td>187.2990599629018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>602347ee-2d81-7ad3-7f85-d68ea1fb8967</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_d</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>55000000.0</td>\n",
       "      <td>---</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.1265939752356</td>\n",
       "      <td>210.17999456981775</td>\n",
       "      <td>176.69071802996686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>-</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>ipo</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.609211688125</td>\n",
       "      <td>212.50173971174402</td>\n",
       "      <td>178.24596607908597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3733 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        funding_round_uuid company_name  \\\n",
       "1     778db45f-e9d1-3f73-86f4-ae4cc79c48ff        Lot18   \n",
       "2     fc2c2560-8bb0-90d1-b048-ee9cfc3f301d        Lot18   \n",
       "3     d863a1b9-dda0-284e-3258-fa43a20d305c        Lot18   \n",
       "4     4c9cb685-ec9a-92ed-64c0-062040d9573e        Lot18   \n",
       "5     1006ef75-d2f2-bac4-5737-dae2075cf616        Lot18   \n",
       "...                                    ...          ...   \n",
       "3729  80f5449a-2b38-f3eb-dc4f-d5b581e636ec    ZS Pharma   \n",
       "3730  e79c29e1-b5a7-db70-014d-36c2ba16338b    ZS Pharma   \n",
       "3731  2067db69-a274-7914-0207-5fb1af6cc7ca    ZS Pharma   \n",
       "3732  602347ee-2d81-7ad3-7f85-d68ea1fb8967    ZS Pharma   \n",
       "3733                                     -    ZS Pharma   \n",
       "\n",
       "                              company_uuid investment_type announced_on  \\\n",
       "1     003d89d4-47dc-e35a-ddf6-eda9940f3ba7            seed   2010-01-01   \n",
       "2     003d89d4-47dc-e35a-ddf6-eda9940f3ba7        series_a   2010-11-10   \n",
       "3     003d89d4-47dc-e35a-ddf6-eda9940f3ba7        series_b   2011-05-02   \n",
       "4     003d89d4-47dc-e35a-ddf6-eda9940f3ba7  series_unknown   2011-08-24   \n",
       "5     003d89d4-47dc-e35a-ddf6-eda9940f3ba7        series_c   2011-11-04   \n",
       "...                                    ...             ...          ...   \n",
       "3729  ffd3e2ec-f764-6135-4b41-9a861965223d  series_unknown   2010-12-14   \n",
       "3730  ffd3e2ec-f764-6135-4b41-9a861965223d  series_unknown   2010-12-20   \n",
       "3731  ffd3e2ec-f764-6135-4b41-9a861965223d        series_c   2012-10-23   \n",
       "3732  ffd3e2ec-f764-6135-4b41-9a861965223d        series_d   2014-03-05   \n",
       "3733  ffd3e2ec-f764-6135-4b41-9a861965223d             ipo   2014-06-19   \n",
       "\n",
       "     raised_amount_usd post_money_valuation_usd   exit_date exit_type  \\\n",
       "1             500000.0                      ---         ---       ---   \n",
       "2            3000000.0                      ---         ---       ---   \n",
       "3           10000000.0                      ---         ---       ---   \n",
       "4            1000000.0                      ---         ---       ---   \n",
       "5           30000000.0                      ---         ---       ---   \n",
       "...                ...                      ...         ...       ...   \n",
       "3729         1195972.0                      ---  2014-06-19       ipo   \n",
       "3730          792000.0                      ---  2014-06-19       ipo   \n",
       "3731        46000000.0                      ---  2014-06-19       ipo   \n",
       "3732        55000000.0                      ---  2014-06-19       ipo   \n",
       "3733       112000000.0              300000000.0  2014-06-19       ipo   \n",
       "\n",
       "        price_usd money_raised_usd  time_from_2009  time_from_start  \\\n",
       "1             ---              ---           365.0              0.0   \n",
       "2             ---              ---           678.0            313.0   \n",
       "3             ---              ---           851.0            486.0   \n",
       "4             ---              ---           965.0            600.0   \n",
       "5             ---              ---          1037.0            672.0   \n",
       "...           ...              ...             ...              ...   \n",
       "3729  300000000.0      112000000.0           712.0              0.0   \n",
       "3730  300000000.0      112000000.0           718.0              6.0   \n",
       "3731  300000000.0      112000000.0          1391.0            679.0   \n",
       "3732  300000000.0      112000000.0          1889.0           1177.0   \n",
       "3733  300000000.0      112000000.0          1995.0           1283.0   \n",
       "\n",
       "     time_from_previous  top_investor  other_investor  top_investor_count  \\\n",
       "1                   ---           0.0             0.0                 0.0   \n",
       "2                 313.0           1.0             0.0                 3.0   \n",
       "3                 173.0           1.0             0.0                 3.0   \n",
       "4                 114.0           0.0             1.0                 3.0   \n",
       "5                  72.0           1.0             0.0                 3.0   \n",
       "...                 ...           ...             ...                 ...   \n",
       "3729                ---           0.0             0.0                 0.0   \n",
       "3730                6.0           0.0             1.0                 4.0   \n",
       "3731              673.0           1.0             1.0                 4.0   \n",
       "3732              498.0           1.0             1.0                 4.0   \n",
       "3733              106.0           0.0             0.0                 0.0   \n",
       "\n",
       "      other_investor_count  top_investor_sum  other_investor_sum  \\\n",
       "1                      0.0               0.0                 0.0   \n",
       "2                      2.0               6.0                 2.0   \n",
       "3                      2.0               6.0                 2.0   \n",
       "4                      2.0               6.0                 2.0   \n",
       "5                      2.0               6.0                 2.0   \n",
       "...                    ...               ...                 ...   \n",
       "3729                   0.0               0.0                 0.0   \n",
       "3730                   6.0               5.0                11.0   \n",
       "3731                   6.0               5.0                11.0   \n",
       "3732                   6.0               5.0                11.0   \n",
       "3733                   0.0               0.0                 0.0   \n",
       "\n",
       "      top_investor_rounds  other_investor_rounds total_count  count_per_round  \\\n",
       "1                     3.0                    1.0         9.0              2.0   \n",
       "2                     3.0                    1.0         9.0              3.0   \n",
       "3                     3.0                    1.0         9.0              4.0   \n",
       "4                     3.0                    1.0         9.0              4.0   \n",
       "5                     3.0                    1.0         9.0              4.0   \n",
       "...                   ...                    ...         ...              ...   \n",
       "3729                  2.0                    3.0         9.0              6.0   \n",
       "3730                  2.0                    3.0         9.0              6.0   \n",
       "3731                  2.0                    3.0         9.0              6.0   \n",
       "3732                  2.0                    3.0         9.0              9.0   \n",
       "3733                  2.0                    3.0         9.0              9.0   \n",
       "\n",
       "     from_top5_count PHD_count Master_count MBA_count     exp_months_min  \\\n",
       "1                0.0       0.0          1.0       1.0  135.0335735846732   \n",
       "2                0.0       0.0          1.0       1.0  53.32347686810817   \n",
       "3                0.0       0.0          2.0       2.0                0.0   \n",
       "4                0.0       0.0          2.0       2.0                0.0   \n",
       "5                0.0       0.0          2.0       2.0                0.0   \n",
       "...              ...       ...          ...       ...                ...   \n",
       "3729             2.0       1.0          0.0       1.0                0.0   \n",
       "3730             2.0       1.0          0.0       1.0                0.0   \n",
       "3731             2.0       1.0          0.0       1.0                0.0   \n",
       "3732             3.0       2.0          1.0       3.0                0.0   \n",
       "3733             3.0       2.0          1.0       3.0                0.0   \n",
       "\n",
       "          exp_months_max     exp_months_mean      exp_months_std  \n",
       "1     199.03488778003654  167.03423068235486   45.25576327239227  \n",
       "2     209.31846649828537   135.9863652231052    78.4149659700011  \n",
       "3     215.00236144479354     106.25269512721   95.48239059035497  \n",
       "4      218.7478182303538  109.06178771638022    96.8798428111566  \n",
       "5      221.1133698843919  110.83595145690877    97.7706351449893  \n",
       "...                  ...                 ...                 ...  \n",
       "3729  426.45639540852994    140.553194110762   176.5474614109795  \n",
       "3730   426.6535247130331   140.6517587630136  176.64163261454254  \n",
       "3731   448.7648617014723   151.7074272572332   187.2990599629018  \n",
       "3732   465.1265939752356  210.17999456981775  176.69071802996686  \n",
       "3733    468.609211688125  212.50173971174402  178.24596607908597  \n",
       "\n",
       "[3733 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#wave_1\n",
    "dataset = pd.read_csv('C:/Users/Barca/Desktop/GitHub/IPO_Analysis/model_ver_based_on_2019/wave_1/2_SocialGraph/people_one_hot.csv')\n",
    "dataset = dataset.iloc[1:]\n",
    "dataset = dataset.rename(columns={'experience_in_months': 'exp_months_min', 'experience_in_months.1': 'exp_months_max', 'experience_in_months.2': 'exp_months_mean', 'experience_in_months.3': 'exp_months_std', 'is_PHD': 'PHD_count', 'is_Master': 'Master_count', 'is_MBA': 'MBA_count', 'top_quantil': 'from_top5_count'})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barca\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:726: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funding_round_uuid</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_uuid</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>announced_on</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>post_money_valuation_usd</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>exit_type</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>money_raised_usd</th>\n",
       "      <th>time_from_2009</th>\n",
       "      <th>time_from_start</th>\n",
       "      <th>time_from_previous</th>\n",
       "      <th>top_investor</th>\n",
       "      <th>other_investor</th>\n",
       "      <th>top_investor_count</th>\n",
       "      <th>other_investor_count</th>\n",
       "      <th>top_investor_sum</th>\n",
       "      <th>other_investor_sum</th>\n",
       "      <th>top_investor_rounds</th>\n",
       "      <th>other_investor_rounds</th>\n",
       "      <th>total_count</th>\n",
       "      <th>count_per_round</th>\n",
       "      <th>from_top5_count</th>\n",
       "      <th>PHD_count</th>\n",
       "      <th>Master_count</th>\n",
       "      <th>MBA_count</th>\n",
       "      <th>exp_months_min</th>\n",
       "      <th>exp_months_max</th>\n",
       "      <th>exp_months_mean</th>\n",
       "      <th>exp_months_std</th>\n",
       "      <th>interpolated_money_valuation_usd</th>\n",
       "      <th>total_sum_raised</th>\n",
       "      <th>total_sum_raised_before</th>\n",
       "      <th>valuation</th>\n",
       "      <th>lnP</th>\n",
       "      <th>log_delta</th>\n",
       "      <th>not_dead</th>\n",
       "      <th>val_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fc2c2560-8bb0-90d1-b048-ee9cfc3f301d</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_a</td>\n",
       "      <td>2010-11-10</td>\n",
       "      <td>3000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>678.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>313.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.32347686810817</td>\n",
       "      <td>209.31846649828537</td>\n",
       "      <td>135.9863652231052</td>\n",
       "      <td>78.4149659700011</td>\n",
       "      <td>1.800000e+07</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>500000.0</td>\n",
       "      <td>1.800000e+07</td>\n",
       "      <td>16.705882</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.562259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d863a1b9-dda0-284e-3258-fa43a20d305c</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_b</td>\n",
       "      <td>2011-05-02</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>851.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.00236144479354</td>\n",
       "      <td>106.25269512721</td>\n",
       "      <td>95.48239059035497</td>\n",
       "      <td>6.800000e+07</td>\n",
       "      <td>13500000.0</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>6.800000e+07</td>\n",
       "      <td>18.035018</td>\n",
       "      <td>1.329136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.804246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4c9cb685-ec9a-92ed-64c0-062040d9573e</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_unknown</td>\n",
       "      <td>2011-08-24</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>965.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>218.7478182303538</td>\n",
       "      <td>109.06178771638022</td>\n",
       "      <td>96.8798428111566</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>13500000.0</td>\n",
       "      <td>5.000000e+06</td>\n",
       "      <td>15.424948</td>\n",
       "      <td>-2.610070</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.356802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1006ef75-d2f2-bac4-5737-dae2075cf616</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2011-11-04</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.1133698843919</td>\n",
       "      <td>110.83595145690877</td>\n",
       "      <td>97.7706351449893</td>\n",
       "      <td>2.320000e+08</td>\n",
       "      <td>44500000.0</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>2.320000e+08</td>\n",
       "      <td>19.262248</td>\n",
       "      <td>3.837299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.452976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>death</td>\n",
       "      <td>2014-12-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2182.0</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.69329965707715</td>\n",
       "      <td>147.8031718652676</td>\n",
       "      <td>134.71217783680558</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>44500000.0</td>\n",
       "      <td>44500000.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19.262248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.140367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>-</td>\n",
       "      <td>Aster Data Systems</td>\n",
       "      <td>ff65b5a2-e2f4-1557-b091-e93dfe88873e</td>\n",
       "      <td>sold</td>\n",
       "      <td>2011-03-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263000000.0</td>\n",
       "      <td>2011-03-03</td>\n",
       "      <td>sold</td>\n",
       "      <td>263000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>791.0</td>\n",
       "      <td>1948.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.99716626624777</td>\n",
       "      <td>326.01901476416356</td>\n",
       "      <td>200.52978500585226</td>\n",
       "      <td>81.3435196277831</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>53000000.0</td>\n",
       "      <td>53000000.0</td>\n",
       "      <td>2.630000e+08</td>\n",
       "      <td>19.387665</td>\n",
       "      <td>0.125417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.282575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>e79c29e1-b5a7-db70-014d-36c2ba16338b</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_unknown</td>\n",
       "      <td>2010-12-20</td>\n",
       "      <td>792000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>718.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.6535247130331</td>\n",
       "      <td>140.6517587630136</td>\n",
       "      <td>176.64163261454254</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>1987972.0</td>\n",
       "      <td>1195972.0</td>\n",
       "      <td>4.000000e+06</td>\n",
       "      <td>15.201805</td>\n",
       "      <td>-0.405465</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-24.665794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>2067db69-a274-7914-0207-5fb1af6cc7ca</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2012-10-23</td>\n",
       "      <td>46000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>448.7648617014723</td>\n",
       "      <td>151.7074272572332</td>\n",
       "      <td>187.2990599629018</td>\n",
       "      <td>3.740000e+08</td>\n",
       "      <td>47987972.0</td>\n",
       "      <td>1987972.0</td>\n",
       "      <td>3.740000e+08</td>\n",
       "      <td>19.739766</td>\n",
       "      <td>4.537961</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.461153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>602347ee-2d81-7ad3-7f85-d68ea1fb8967</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_d</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>55000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.1265939752356</td>\n",
       "      <td>210.17999456981775</td>\n",
       "      <td>176.69071802996686</td>\n",
       "      <td>4.560000e+08</td>\n",
       "      <td>102987972.0</td>\n",
       "      <td>47987972.0</td>\n",
       "      <td>4.560000e+08</td>\n",
       "      <td>19.938003</td>\n",
       "      <td>0.198237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>-</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>ipo</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.609211688125</td>\n",
       "      <td>212.50173971174402</td>\n",
       "      <td>178.24596607908597</td>\n",
       "      <td>1.011000e+09</td>\n",
       "      <td>214987972.0</td>\n",
       "      <td>102987972.0</td>\n",
       "      <td>1.011000e+09</td>\n",
       "      <td>20.734206</td>\n",
       "      <td>0.796202</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.741640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2645 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        funding_round_uuid        company_name  \\\n",
       "2     fc2c2560-8bb0-90d1-b048-ee9cfc3f301d               Lot18   \n",
       "3     d863a1b9-dda0-284e-3258-fa43a20d305c               Lot18   \n",
       "4     4c9cb685-ec9a-92ed-64c0-062040d9573e               Lot18   \n",
       "5     1006ef75-d2f2-bac4-5737-dae2075cf616               Lot18   \n",
       "6                                        -               Lot18   \n",
       "...                                    ...                 ...   \n",
       "3728                                     -  Aster Data Systems   \n",
       "3730  e79c29e1-b5a7-db70-014d-36c2ba16338b           ZS Pharma   \n",
       "3731  2067db69-a274-7914-0207-5fb1af6cc7ca           ZS Pharma   \n",
       "3732  602347ee-2d81-7ad3-7f85-d68ea1fb8967           ZS Pharma   \n",
       "3733                                     -           ZS Pharma   \n",
       "\n",
       "                              company_uuid investment_type announced_on  \\\n",
       "2     003d89d4-47dc-e35a-ddf6-eda9940f3ba7        series_a   2010-11-10   \n",
       "3     003d89d4-47dc-e35a-ddf6-eda9940f3ba7        series_b   2011-05-02   \n",
       "4     003d89d4-47dc-e35a-ddf6-eda9940f3ba7  series_unknown   2011-08-24   \n",
       "5     003d89d4-47dc-e35a-ddf6-eda9940f3ba7        series_c   2011-11-04   \n",
       "6     003d89d4-47dc-e35a-ddf6-eda9940f3ba7           death   2014-12-23   \n",
       "...                                    ...             ...          ...   \n",
       "3728  ff65b5a2-e2f4-1557-b091-e93dfe88873e            sold   2011-03-03   \n",
       "3730  ffd3e2ec-f764-6135-4b41-9a861965223d  series_unknown   2010-12-20   \n",
       "3731  ffd3e2ec-f764-6135-4b41-9a861965223d        series_c   2012-10-23   \n",
       "3732  ffd3e2ec-f764-6135-4b41-9a861965223d        series_d   2014-03-05   \n",
       "3733  ffd3e2ec-f764-6135-4b41-9a861965223d             ipo   2014-06-19   \n",
       "\n",
       "      raised_amount_usd  post_money_valuation_usd   exit_date exit_type  \\\n",
       "2             3000000.0                       0.0         NaN      dead   \n",
       "3            10000000.0                       0.0         NaN      dead   \n",
       "4             1000000.0                       0.0         NaN      dead   \n",
       "5            30000000.0                       0.0         NaN      dead   \n",
       "6                   0.0                       0.0         NaN      dead   \n",
       "...                 ...                       ...         ...       ...   \n",
       "3728                0.0               263000000.0  2011-03-03      sold   \n",
       "3730           792000.0                       0.0  2014-06-19       ipo   \n",
       "3731         46000000.0                       0.0  2014-06-19       ipo   \n",
       "3732         55000000.0                       0.0  2014-06-19       ipo   \n",
       "3733        112000000.0               300000000.0  2014-06-19       ipo   \n",
       "\n",
       "        price_usd money_raised_usd  time_from_2009  time_from_start  \\\n",
       "2             NaN              NaN           678.0            313.0   \n",
       "3             NaN              NaN           851.0            486.0   \n",
       "4             NaN              NaN           965.0            600.0   \n",
       "5             NaN              NaN          1037.0            672.0   \n",
       "6             NaN              NaN          2182.0           1817.0   \n",
       "...           ...              ...             ...              ...   \n",
       "3728  263000000.0              NaN           791.0           1948.0   \n",
       "3730  300000000.0      112000000.0           718.0              6.0   \n",
       "3731  300000000.0      112000000.0          1391.0            679.0   \n",
       "3732  300000000.0      112000000.0          1889.0           1177.0   \n",
       "3733  300000000.0      112000000.0          1995.0           1283.0   \n",
       "\n",
       "      time_from_previous  top_investor  other_investor  top_investor_count  \\\n",
       "2                  313.0           1.0             0.0                 3.0   \n",
       "3                  173.0           1.0             0.0                 3.0   \n",
       "4                  114.0           0.0             1.0                 3.0   \n",
       "5                   72.0           1.0             0.0                 3.0   \n",
       "6                 1145.0           0.0             0.0                 0.0   \n",
       "...                  ...           ...             ...                 ...   \n",
       "3728               162.0           0.0             0.0                 0.0   \n",
       "3730                 6.0           0.0             1.0                 4.0   \n",
       "3731               673.0           1.0             1.0                 4.0   \n",
       "3732               498.0           1.0             1.0                 4.0   \n",
       "3733               106.0           0.0             0.0                 0.0   \n",
       "\n",
       "      other_investor_count  top_investor_sum  other_investor_sum  \\\n",
       "2                      2.0               6.0                 2.0   \n",
       "3                      2.0               6.0                 2.0   \n",
       "4                      2.0               6.0                 2.0   \n",
       "5                      2.0               6.0                 2.0   \n",
       "6                      0.0               0.0                 0.0   \n",
       "...                    ...               ...                 ...   \n",
       "3728                   0.0               0.0                 0.0   \n",
       "3730                   6.0               5.0                11.0   \n",
       "3731                   6.0               5.0                11.0   \n",
       "3732                   6.0               5.0                11.0   \n",
       "3733                   0.0               0.0                 0.0   \n",
       "\n",
       "      top_investor_rounds  other_investor_rounds total_count  count_per_round  \\\n",
       "2                     3.0                    1.0         9.0              3.0   \n",
       "3                     3.0                    1.0         9.0              4.0   \n",
       "4                     3.0                    1.0         9.0              4.0   \n",
       "5                     3.0                    1.0         9.0              4.0   \n",
       "6                     3.0                    1.0         9.0              3.0   \n",
       "...                   ...                    ...         ...              ...   \n",
       "3728                  4.0                    4.0        11.0             10.0   \n",
       "3730                  2.0                    3.0         9.0              6.0   \n",
       "3731                  2.0                    3.0         9.0              6.0   \n",
       "3732                  2.0                    3.0         9.0              9.0   \n",
       "3733                  2.0                    3.0         9.0              9.0   \n",
       "\n",
       "     from_top5_count PHD_count Master_count MBA_count     exp_months_min  \\\n",
       "2                0.0       0.0          1.0       1.0  53.32347686810817   \n",
       "3                0.0       0.0          2.0       2.0                0.0   \n",
       "4                0.0       0.0          2.0       2.0                0.0   \n",
       "5                0.0       0.0          2.0       2.0                0.0   \n",
       "6                1.0       0.0          1.0       1.0                0.0   \n",
       "...              ...       ...          ...       ...                ...   \n",
       "3728             6.0       2.0          4.0       2.0  61.99716626624777   \n",
       "3730             2.0       1.0          0.0       1.0                0.0   \n",
       "3731             2.0       1.0          0.0       1.0                0.0   \n",
       "3732             3.0       2.0          1.0       3.0                0.0   \n",
       "3733             3.0       2.0          1.0       3.0                0.0   \n",
       "\n",
       "          exp_months_max     exp_months_mean      exp_months_std  \\\n",
       "2     209.31846649828537   135.9863652231052    78.4149659700011   \n",
       "3     215.00236144479354     106.25269512721   95.48239059035497   \n",
       "4      218.7478182303538  109.06178771638022    96.8798428111566   \n",
       "5      221.1133698843919  110.83595145690877    97.7706351449893   \n",
       "6     263.69329965707715   147.8031718652676  134.71217783680558   \n",
       "...                  ...                 ...                 ...   \n",
       "3728  326.01901476416356  200.52978500585226    81.3435196277831   \n",
       "3730   426.6535247130331   140.6517587630136  176.64163261454254   \n",
       "3731   448.7648617014723   151.7074272572332   187.2990599629018   \n",
       "3732   465.1265939752356  210.17999456981775  176.69071802996686   \n",
       "3733    468.609211688125  212.50173971174402  178.24596607908597   \n",
       "\n",
       "      interpolated_money_valuation_usd  total_sum_raised  \\\n",
       "2                         1.800000e+07         3500000.0   \n",
       "3                         6.800000e+07        13500000.0   \n",
       "4                         5.000000e+06        14500000.0   \n",
       "5                         2.320000e+08        44500000.0   \n",
       "6                         0.000000e+00        44500000.0   \n",
       "...                                ...               ...   \n",
       "3728                      0.000000e+00        53000000.0   \n",
       "3730                      4.000000e+06         1987972.0   \n",
       "3731                      3.740000e+08        47987972.0   \n",
       "3732                      4.560000e+08       102987972.0   \n",
       "3733                      1.011000e+09       214987972.0   \n",
       "\n",
       "      total_sum_raised_before     valuation        lnP  log_delta  not_dead  \\\n",
       "2                    500000.0  1.800000e+07  16.705882   2.197225       0.0   \n",
       "3                   3500000.0  6.800000e+07  18.035018   1.329136       0.0   \n",
       "4                  13500000.0  5.000000e+06  15.424948  -2.610070       0.0   \n",
       "5                  14500000.0  2.320000e+08  19.262248   3.837299       0.0   \n",
       "6                  44500000.0  1.000000e+00   0.000000 -19.262248       0.0   \n",
       "...                       ...           ...        ...        ...       ...   \n",
       "3728               53000000.0  2.630000e+08  19.387665   0.125417       1.0   \n",
       "3730                1195972.0  4.000000e+06  15.201805  -0.405465       1.0   \n",
       "3731                1987972.0  3.740000e+08  19.739766   4.537961       1.0   \n",
       "3732               47987972.0  4.560000e+08  19.938003   0.198237       1.0   \n",
       "3733              102987972.0  1.011000e+09  20.734206   0.796202       1.0   \n",
       "\n",
       "       val_rate  \n",
       "2      2.562259  \n",
       "3      2.804246  \n",
       "4     -8.356802  \n",
       "5     19.452976  \n",
       "6     -6.140367  \n",
       "...         ...  \n",
       "3728   0.282575  \n",
       "3730 -24.665794  \n",
       "3731   2.461153  \n",
       "3732   0.145294  \n",
       "3733   2.741640  \n",
       "\n",
       "[2645 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['raised_amount_usd'] = pd.to_numeric(dataset['raised_amount_usd'], errors='coerce')\n",
    "dataset.loc[dataset['raised_amount_usd'].isin(nan), 'raised_amount_usd'] = 0\n",
    "dataset['interpolated_money_valuation_usd'] = round(dataset['raised_amount_usd'] ** 1.1187, -6) #1.12751583465595\n",
    "dataset['interpolated_money_valuation_usd'] = pd.to_numeric(dataset['interpolated_money_valuation_usd'], errors='coerce')\n",
    "dataset.loc[dataset['interpolated_money_valuation_usd'].isin(nan), 'interpolated_money_valuation_usd'] = 0\n",
    "dataset['post_money_valuation_usd'] = pd.to_numeric(dataset['post_money_valuation_usd'], errors='coerce')\n",
    "dataset.loc[dataset['post_money_valuation_usd'].isin(nan), 'post_money_valuation_usd'] = 0\n",
    "\n",
    "dataset['total_sum_raised'] = dataset.groupby(['company_uuid'])['raised_amount_usd'].transform('cumsum')\n",
    "dataset['total_sum_raised_before'] = dataset.groupby('company_uuid')['total_sum_raised'].shift(1)\n",
    "\n",
    "dataset['valuation'] = dataset['interpolated_money_valuation_usd']\n",
    "dataset.loc[dataset['valuation'] == 0, 'valuation'] = dataset['post_money_valuation_usd']\n",
    "dataset.loc[dataset['investment_type'] == 'death', 'valuation'] = default_exit_value\n",
    "\n",
    "dataset.loc[dataset['valuation'] != 0, 'lnP'] = np.log(dataset['valuation'])\n",
    "dataset = dataset.loc[~dataset['lnP'].isin(nan)]\n",
    "dataset['log_delta'] = dataset.groupby(['company_uuid'])['lnP'].diff()\n",
    "dataset = dataset.loc[~dataset['log_delta'].isin(nan)]\n",
    "\n",
    "dataset = dataset.replace('---', np.nan)\n",
    "dataset.loc[(dataset['exit_type'].isin(nan)) | (dataset['exit_type'] == '0'), 'exit_type'] = 'dead'\n",
    "dataset.loc[dataset['exit_type'] == 'dead', 'not_dead'] = 0\n",
    "dataset.loc[dataset['exit_type'].isin(['sold', 'ipo']), 'not_dead'] = 1\n",
    "\n",
    "dataset['announced_on'] = pd.to_datetime(dataset['announced_on'])\n",
    "dataset['log_delta'] = pd.to_numeric(dataset['log_delta'], errors='coerce')\n",
    "dataset['time_from_previous'] = pd.to_numeric(dataset['time_from_previous'], errors='coerce')\n",
    "dataset['val_rate'] = dataset['log_delta'] * (365 / dataset['time_from_previous'])\n",
    "\n",
    "listColumns = ['from_top5_count', 'PHD_count', 'Master_count', 'MBA_count']\n",
    "for i in listColumns:\n",
    "    dataset[i] = dataset[i].replace(np.nan, 0)\n",
    "\n",
    "#for i in dataset.columns:\n",
    "#    if i.startswith('EDU_'):\n",
    "#        dataset[i] = pd.to_numeric(dataset[i], errors='coerce')\n",
    "#        dataset.loc[dataset[i] != 0, i] = 1\n",
    "\n",
    "y = dataset.loc[dataset['investment_type'].isin(['ipo', 'sold', 'death'])] #экзиты\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем на классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y['val_rate'].describe([.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.groupby('investment_type').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все, что слева от медианного значения -0.9 - нарвалы (с отрицательной скоростью роста привлеченных средств), справа - носороги (с положительной и околонулевой скоростью роста привлеченных средств)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funding_round_uuid</th>\n",
       "      <th>company_name</th>\n",
       "      <th>company_uuid</th>\n",
       "      <th>investment_type</th>\n",
       "      <th>announced_on</th>\n",
       "      <th>raised_amount_usd</th>\n",
       "      <th>post_money_valuation_usd</th>\n",
       "      <th>exit_date</th>\n",
       "      <th>exit_type</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>money_raised_usd</th>\n",
       "      <th>time_from_2009</th>\n",
       "      <th>time_from_start</th>\n",
       "      <th>time_from_previous</th>\n",
       "      <th>top_investor</th>\n",
       "      <th>other_investor</th>\n",
       "      <th>top_investor_count</th>\n",
       "      <th>other_investor_count</th>\n",
       "      <th>top_investor_sum</th>\n",
       "      <th>other_investor_sum</th>\n",
       "      <th>top_investor_rounds</th>\n",
       "      <th>other_investor_rounds</th>\n",
       "      <th>total_count</th>\n",
       "      <th>count_per_round</th>\n",
       "      <th>from_top5_count</th>\n",
       "      <th>PHD_count</th>\n",
       "      <th>Master_count</th>\n",
       "      <th>MBA_count</th>\n",
       "      <th>exp_months_min</th>\n",
       "      <th>exp_months_max</th>\n",
       "      <th>exp_months_mean</th>\n",
       "      <th>exp_months_std</th>\n",
       "      <th>interpolated_money_valuation_usd</th>\n",
       "      <th>total_sum_raised</th>\n",
       "      <th>total_sum_raised_before</th>\n",
       "      <th>valuation</th>\n",
       "      <th>lnP</th>\n",
       "      <th>log_delta</th>\n",
       "      <th>not_dead</th>\n",
       "      <th>val_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1006ef75-d2f2-bac4-5737-dae2075cf616</td>\n",
       "      <td>Lot18</td>\n",
       "      <td>003d89d4-47dc-e35a-ddf6-eda9940f3ba7</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2011-11-04</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.1133698843919</td>\n",
       "      <td>110.83595145690877</td>\n",
       "      <td>97.7706351449893</td>\n",
       "      <td>2.320000e+08</td>\n",
       "      <td>44500000.0</td>\n",
       "      <td>14500000.0</td>\n",
       "      <td>2.320000e+08</td>\n",
       "      <td>19.262248</td>\n",
       "      <td>3.837299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.452976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>951e44e7-27c6-b933-eb05-160c03705497</td>\n",
       "      <td>CellBiosciences</td>\n",
       "      <td>00e12273-bfa7-d0ac-25e2-c870ab22c474</td>\n",
       "      <td>series_f</td>\n",
       "      <td>2010-10-14</td>\n",
       "      <td>20000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-06-17</td>\n",
       "      <td>sold</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>651.0</td>\n",
       "      <td>1747.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>508.42933119776586</td>\n",
       "      <td>205.88330584018382</td>\n",
       "      <td>174.47653250404431</td>\n",
       "      <td>1.470000e+08</td>\n",
       "      <td>85249999.0</td>\n",
       "      <td>65249999.0</td>\n",
       "      <td>1.470000e+08</td>\n",
       "      <td>18.805943</td>\n",
       "      <td>0.863298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.060956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6eca3823-4c26-250a-b7e5-c82666deadb2</td>\n",
       "      <td>Box</td>\n",
       "      <td>022bddcc-e01a-a6de-91e9-b93cfcc5a9ee</td>\n",
       "      <td>series_g</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>150000000.0</td>\n",
       "      <td>2.400000e+09</td>\n",
       "      <td>2015-01-23</td>\n",
       "      <td>ipo</td>\n",
       "      <td>1670000000.0</td>\n",
       "      <td>175000000.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>3225.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>557.9744963962299</td>\n",
       "      <td>227.72209486585632</td>\n",
       "      <td>130.6148736020432</td>\n",
       "      <td>1.402000e+09</td>\n",
       "      <td>558950000.0</td>\n",
       "      <td>408950000.0</td>\n",
       "      <td>1.402000e+09</td>\n",
       "      <td>21.061166</td>\n",
       "      <td>0.454434</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.797444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a58a8f80-6b14-2e6c-ddb9-b96ca2c08b14</td>\n",
       "      <td>Amonix</td>\n",
       "      <td>028f2da1-4fe1-1a99-e15c-852f2fb37700</td>\n",
       "      <td>series_b</td>\n",
       "      <td>2010-04-21</td>\n",
       "      <td>129400000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>475.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>109.66960307193166</td>\n",
       "      <td>459.63982833323064</td>\n",
       "      <td>321.32076634017125</td>\n",
       "      <td>186.15312903745684</td>\n",
       "      <td>1.188000e+09</td>\n",
       "      <td>154400000.0</td>\n",
       "      <td>25000000.0</td>\n",
       "      <td>1.188000e+09</td>\n",
       "      <td>20.895537</td>\n",
       "      <td>1.838279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.533595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1fbd2706-f158-b41d-55e4-aaccf14957e8</td>\n",
       "      <td>Motif</td>\n",
       "      <td>02c6c841-a03a-79ed-9b19-87bb3998ff82</td>\n",
       "      <td>series_e</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>40000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2210.0</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>120.61027947185774</td>\n",
       "      <td>751.6540380705969</td>\n",
       "      <td>339.484041424533</td>\n",
       "      <td>217.3367756185948</td>\n",
       "      <td>3.190000e+08</td>\n",
       "      <td>126500000.0</td>\n",
       "      <td>86500000.0</td>\n",
       "      <td>3.190000e+08</td>\n",
       "      <td>19.580702</td>\n",
       "      <td>0.148420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689</th>\n",
       "      <td>96dacb4d-a74f-65b3-aabc-7f6b926fd62e</td>\n",
       "      <td>Leyden Energy</td>\n",
       "      <td>fd5884b9-3586-d156-cf31-899db2084f70</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>10000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dead</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1483.0</td>\n",
       "      <td>2035.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>132.73373169880284</td>\n",
       "      <td>415.77855808127475</td>\n",
       "      <td>249.08382786778645</td>\n",
       "      <td>111.33437118747031</td>\n",
       "      <td>6.800000e+07</td>\n",
       "      <td>46801000.0</td>\n",
       "      <td>36801000.0</td>\n",
       "      <td>6.800000e+07</td>\n",
       "      <td>18.035018</td>\n",
       "      <td>-0.770925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.522055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3702</th>\n",
       "      <td>2e501c03-d6d4-8de9-7f2e-12b1affc65cb</td>\n",
       "      <td>Marinus Pharmaceuticals</td>\n",
       "      <td>fe162dcb-8475-f00f-0c3a-aa14032c6abf</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>21000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-07-21</td>\n",
       "      <td>ipo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45000000.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>2631.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>547.2638041848909</td>\n",
       "      <td>279.0570648267932</td>\n",
       "      <td>199.8803090941823</td>\n",
       "      <td>1.550000e+08</td>\n",
       "      <td>81835690.0</td>\n",
       "      <td>60835690.0</td>\n",
       "      <td>1.550000e+08</td>\n",
       "      <td>18.858936</td>\n",
       "      <td>0.673977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.947458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>c9114172-7a01-695f-7c32-2807c58cd8a7</td>\n",
       "      <td>Juno Therapeutics</td>\n",
       "      <td>ff429091-2166-c3b5-409d-6e779fee09f5</td>\n",
       "      <td>series_b</td>\n",
       "      <td>2014-08-05</td>\n",
       "      <td>134000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-12-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>1675700000.0</td>\n",
       "      <td>264600000.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>626.1483808702437</td>\n",
       "      <td>249.10846903084936</td>\n",
       "      <td>189.1148550454083</td>\n",
       "      <td>1.235000e+09</td>\n",
       "      <td>310000000.0</td>\n",
       "      <td>176000000.0</td>\n",
       "      <td>1.235000e+09</td>\n",
       "      <td>20.934337</td>\n",
       "      <td>0.976789</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.461436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>32ea83d9-9fe1-c480-c503-25eece562607</td>\n",
       "      <td>Aster Data Systems</td>\n",
       "      <td>ff65b5a2-e2f4-1557-b091-e93dfe88873e</td>\n",
       "      <td>series_c</td>\n",
       "      <td>2010-09-22</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2011-03-03</td>\n",
       "      <td>sold</td>\n",
       "      <td>263000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>629.0</td>\n",
       "      <td>1786.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>56.67467504466211</td>\n",
       "      <td>320.6965235425779</td>\n",
       "      <td>195.20729378426662</td>\n",
       "      <td>81.34351962778311</td>\n",
       "      <td>2.320000e+08</td>\n",
       "      <td>53000000.0</td>\n",
       "      <td>23000000.0</td>\n",
       "      <td>2.320000e+08</td>\n",
       "      <td>19.262248</td>\n",
       "      <td>0.634553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.403505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>602347ee-2d81-7ad3-7f85-d68ea1fb8967</td>\n",
       "      <td>ZS Pharma</td>\n",
       "      <td>ffd3e2ec-f764-6135-4b41-9a861965223d</td>\n",
       "      <td>series_d</td>\n",
       "      <td>2014-03-05</td>\n",
       "      <td>55000000.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2014-06-19</td>\n",
       "      <td>ipo</td>\n",
       "      <td>300000000.0</td>\n",
       "      <td>112000000.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>1177.0</td>\n",
       "      <td>498.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>465.1265939752356</td>\n",
       "      <td>210.17999456981775</td>\n",
       "      <td>176.69071802996686</td>\n",
       "      <td>4.560000e+08</td>\n",
       "      <td>102987972.0</td>\n",
       "      <td>47987972.0</td>\n",
       "      <td>4.560000e+08</td>\n",
       "      <td>19.938003</td>\n",
       "      <td>0.198237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        funding_round_uuid             company_name  \\\n",
       "5     1006ef75-d2f2-bac4-5737-dae2075cf616                    Lot18   \n",
       "12    951e44e7-27c6-b933-eb05-160c03705497          CellBiosciences   \n",
       "24    6eca3823-4c26-250a-b7e5-c82666deadb2                      Box   \n",
       "27    a58a8f80-6b14-2e6c-ddb9-b96ca2c08b14                   Amonix   \n",
       "34    1fbd2706-f158-b41d-55e4-aaccf14957e8                    Motif   \n",
       "...                                    ...                      ...   \n",
       "3689  96dacb4d-a74f-65b3-aabc-7f6b926fd62e            Leyden Energy   \n",
       "3702  2e501c03-d6d4-8de9-7f2e-12b1affc65cb  Marinus Pharmaceuticals   \n",
       "3722  c9114172-7a01-695f-7c32-2807c58cd8a7        Juno Therapeutics   \n",
       "3727  32ea83d9-9fe1-c480-c503-25eece562607       Aster Data Systems   \n",
       "3732  602347ee-2d81-7ad3-7f85-d68ea1fb8967                ZS Pharma   \n",
       "\n",
       "                              company_uuid investment_type announced_on  \\\n",
       "5     003d89d4-47dc-e35a-ddf6-eda9940f3ba7        series_c   2011-11-04   \n",
       "12    00e12273-bfa7-d0ac-25e2-c870ab22c474        series_f   2010-10-14   \n",
       "24    022bddcc-e01a-a6de-91e9-b93cfcc5a9ee        series_g   2014-07-01   \n",
       "27    028f2da1-4fe1-1a99-e15c-852f2fb37700        series_b   2010-04-21   \n",
       "34    02c6c841-a03a-79ed-9b19-87bb3998ff82        series_e   2015-01-20   \n",
       "...                                    ...             ...          ...   \n",
       "3689  fd5884b9-3586-d156-cf31-899db2084f70        series_c   2013-01-23   \n",
       "3702  fe162dcb-8475-f00f-0c3a-aa14032c6abf        series_c   2013-01-07   \n",
       "3722  ff429091-2166-c3b5-409d-6e779fee09f5        series_b   2014-08-05   \n",
       "3727  ff65b5a2-e2f4-1557-b091-e93dfe88873e        series_c   2010-09-22   \n",
       "3732  ffd3e2ec-f764-6135-4b41-9a861965223d        series_d   2014-03-05   \n",
       "\n",
       "      raised_amount_usd  post_money_valuation_usd   exit_date exit_type  \\\n",
       "5            30000000.0              0.000000e+00         NaN      dead   \n",
       "12           20000000.0              0.000000e+00  2014-06-17      sold   \n",
       "24          150000000.0              2.400000e+09  2015-01-23       ipo   \n",
       "27          129400000.0              0.000000e+00         NaN      dead   \n",
       "34           40000000.0              0.000000e+00         NaN      dead   \n",
       "...                 ...                       ...         ...       ...   \n",
       "3689         10000000.0              0.000000e+00         NaN      dead   \n",
       "3702         21000000.0              0.000000e+00  2014-07-21       ipo   \n",
       "3722        134000000.0              0.000000e+00  2014-12-19       ipo   \n",
       "3727         30000000.0              0.000000e+00  2011-03-03      sold   \n",
       "3732         55000000.0              0.000000e+00  2014-06-19       ipo   \n",
       "\n",
       "         price_usd money_raised_usd  time_from_2009  time_from_start  \\\n",
       "5              NaN              NaN          1037.0            672.0   \n",
       "12     300000000.0              NaN           651.0           1747.0   \n",
       "24    1670000000.0      175000000.0          2007.0           3225.0   \n",
       "27             NaN              NaN           475.0            148.0   \n",
       "34             NaN              NaN          2210.0           1602.0   \n",
       "...            ...              ...             ...              ...   \n",
       "3689           NaN              NaN          1483.0           2035.0   \n",
       "3702           NaN       45000000.0          1467.0           2631.0   \n",
       "3722  1675700000.0      264600000.0          2042.0            245.0   \n",
       "3727   263000000.0              NaN           629.0           1786.0   \n",
       "3732   300000000.0      112000000.0          1889.0           1177.0   \n",
       "\n",
       "      time_from_previous  top_investor  other_investor  top_investor_count  \\\n",
       "5                   72.0           1.0             0.0                 3.0   \n",
       "12                 297.0           1.0             1.0                 4.0   \n",
       "24                 208.0           0.0             1.0                10.0   \n",
       "27                 148.0           1.0             1.0                 3.0   \n",
       "34                 257.0           0.0             1.0                 5.0   \n",
       "...                  ...           ...             ...                 ...   \n",
       "3689               539.0           1.0             0.0                 4.0   \n",
       "3702                19.0           1.0             1.0                 3.0   \n",
       "3722               103.0           1.0             1.0                 2.0   \n",
       "3727               574.0           1.0             1.0                 5.0   \n",
       "3732               498.0           1.0             1.0                 4.0   \n",
       "\n",
       "      other_investor_count  top_investor_sum  other_investor_sum  \\\n",
       "5                      2.0               6.0                 2.0   \n",
       "12                     7.0              12.0                12.0   \n",
       "24                    14.0              27.0                17.0   \n",
       "27                     6.0               3.0                 7.0   \n",
       "34                     4.0              15.0                 4.0   \n",
       "...                    ...               ...                 ...   \n",
       "3689                   0.0              12.0                 0.0   \n",
       "3702                   2.0               9.0                 4.0   \n",
       "3722                   2.0               4.0                 4.0   \n",
       "3727                   4.0              11.0                 7.0   \n",
       "3732                   6.0               5.0                11.0   \n",
       "\n",
       "      top_investor_rounds  other_investor_rounds total_count  count_per_round  \\\n",
       "5                     3.0                    1.0         9.0              4.0   \n",
       "12                    4.0                    3.0         9.0              9.0   \n",
       "24                    8.0                    7.0        60.0             47.0   \n",
       "27                    2.0                    2.0         3.0              3.0   \n",
       "34                    5.0                    2.0         7.0              6.0   \n",
       "...                   ...                    ...         ...              ...   \n",
       "3689                  4.0                    0.0         7.0              6.0   \n",
       "3702                  3.0                    4.0         9.0              8.0   \n",
       "3722                  3.0                    3.0        13.0             12.0   \n",
       "3727                  4.0                    4.0        11.0             10.0   \n",
       "3732                  2.0                    3.0         9.0              9.0   \n",
       "\n",
       "     from_top5_count PHD_count Master_count MBA_count      exp_months_min  \\\n",
       "5                0.0       0.0          2.0       2.0                 0.0   \n",
       "12               1.0       1.0          1.0       4.0                 0.0   \n",
       "24              17.0       1.0          9.0      21.0                 0.0   \n",
       "27               1.0       1.0          1.0       1.0  109.66960307193166   \n",
       "34               3.0       0.0          1.0       3.0  120.61027947185774   \n",
       "...              ...       ...          ...       ...                 ...   \n",
       "3689             2.0       0.0          1.0       2.0  132.73373169880284   \n",
       "3702             2.0       0.0          4.0       1.0                 0.0   \n",
       "3722             2.0       1.0          2.0       2.0                 0.0   \n",
       "3727             6.0       2.0          4.0       2.0   56.67467504466211   \n",
       "3732             3.0       2.0          1.0       3.0                 0.0   \n",
       "\n",
       "          exp_months_max     exp_months_mean      exp_months_std  \\\n",
       "5      221.1133698843919  110.83595145690877    97.7706351449893   \n",
       "12    508.42933119776586  205.88330584018382  174.47653250404431   \n",
       "24     557.9744963962299  227.72209486585632   130.6148736020432   \n",
       "27    459.63982833323064  321.32076634017125  186.15312903745684   \n",
       "34     751.6540380705969    339.484041424533   217.3367756185948   \n",
       "...                  ...                 ...                 ...   \n",
       "3689  415.77855808127475  249.08382786778645  111.33437118747031   \n",
       "3702   547.2638041848909   279.0570648267932   199.8803090941823   \n",
       "3722   626.1483808702437  249.10846903084936   189.1148550454083   \n",
       "3727   320.6965235425779  195.20729378426662   81.34351962778311   \n",
       "3732   465.1265939752356  210.17999456981775  176.69071802996686   \n",
       "\n",
       "      interpolated_money_valuation_usd  total_sum_raised  \\\n",
       "5                         2.320000e+08        44500000.0   \n",
       "12                        1.470000e+08        85249999.0   \n",
       "24                        1.402000e+09       558950000.0   \n",
       "27                        1.188000e+09       154400000.0   \n",
       "34                        3.190000e+08       126500000.0   \n",
       "...                                ...               ...   \n",
       "3689                      6.800000e+07        46801000.0   \n",
       "3702                      1.550000e+08        81835690.0   \n",
       "3722                      1.235000e+09       310000000.0   \n",
       "3727                      2.320000e+08        53000000.0   \n",
       "3732                      4.560000e+08       102987972.0   \n",
       "\n",
       "      total_sum_raised_before     valuation        lnP  log_delta  not_dead  \\\n",
       "5                  14500000.0  2.320000e+08  19.262248   3.837299       0.0   \n",
       "12                 65249999.0  1.470000e+08  18.805943   0.863298       1.0   \n",
       "24                408950000.0  1.402000e+09  21.061166   0.454434       1.0   \n",
       "27                 25000000.0  1.188000e+09  20.895537   1.838279       0.0   \n",
       "34                 86500000.0  3.190000e+08  19.580702   0.148420       0.0   \n",
       "...                       ...           ...        ...        ...       ...   \n",
       "3689               36801000.0  6.800000e+07  18.035018  -0.770925       0.0   \n",
       "3702               60835690.0  1.550000e+08  18.858936   0.673977       1.0   \n",
       "3722              176000000.0  1.235000e+09  20.934337   0.976789       1.0   \n",
       "3727               23000000.0  2.320000e+08  19.262248   0.634553       1.0   \n",
       "3732               47987972.0  4.560000e+08  19.938003   0.198237       1.0   \n",
       "\n",
       "       val_rate  \n",
       "5     19.452976  \n",
       "12     1.060956  \n",
       "24     0.797444  \n",
       "27     4.533595  \n",
       "34     0.210791  \n",
       "...         ...  \n",
       "3689  -0.522055  \n",
       "3702  12.947458  \n",
       "3722   3.461436  \n",
       "3727   0.403505  \n",
       "3732   0.145294  \n",
       "\n",
       "[554 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.loc[dataset['company_uuid'].isin(y['company_uuid'].values)]\n",
    "# dataset.loc[dataset.groupby('company_uuid')['val_rate'].shift(-1) <= -0.916257, 'class'] = 'narwhal'\n",
    "# dataset.loc[dataset.groupby('company_uuid')['val_rate'].shift(-1) > -0.916257, 'class'] = 'rhino'\n",
    "\n",
    "additional = dataset.set_index('funding_round_uuid').groupby('company_uuid')['announced_on'].nlargest(2).reset_index()\n",
    "dataset = dataset.loc[dataset['funding_round_uuid'].isin(additional['funding_round_uuid'].values)]\n",
    "# exits = dataset.copy()\n",
    "dataset = dataset.loc[~dataset['investment_type'].isin(['ipo', 'sold', 'death'])] #преэкзиты\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_dead\n",
       "0.0    262\n",
       "1.0    292\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('not_dead').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exit_type\n",
       "dead    262\n",
       "ipo     158\n",
       "sold    134\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('exit_type').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exits = exits.loc[(exits['investment_type'].isin(['ipo', 'sold', 'death'])) & (exits['company_uuid'].isin(dataset['company_uuid']))] #экзиты\n",
    "# exits.loc[exits['val_rate'] <= -0.916257, 'class'] = 'narwhal'\n",
    "# exits.loc[exits['val_rate'] > -0.916257, 'class'] = 'rhino'\n",
    "# exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.groupby('class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выравниваем количество сэмплов в классах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.random.seed(10)\n",
    "#remove_n = 63\n",
    "#\n",
    "#df = dataset.loc[dataset['class'] == 'rhino']\n",
    "#drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "#dataset = dataset.drop(drop_indices)\n",
    "#dataset.groupby('class').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица корреляций и графики взаимной зависимости между признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_tab = dataset.drop(columns=['funding_round_uuid', 'company_name', 'company_uuid', 'announced_on', 'raised_amount_usd', 'post_money_valuation_usd', 'interpolated_money_valuation_usd', 'exit_date', 'price_usd', 'money_raised_usd', 'total_count', 'count_per_round', 'total_sum_raised', 'lnP', 'log_delta', 'investment_type']) #'exit_type', 'not_dead', 'class'\n",
    "# test_tab.loc[test_tab['exit_type'] == 'sold', 'exit_type'] = -1\n",
    "# test_tab.loc[test_tab['exit_type'] == 'dead', 'exit_type'] = 0\n",
    "# test_tab.loc[test_tab['exit_type'] == 'ipo', 'exit_type'] = 1\n",
    "# test_tab.loc[test_tab['class'] == 'narwhal', 'class'] = 0\n",
    "# test_tab.loc[test_tab['class'] == 'rhino', 'class'] = 1\n",
    "# test_tab = test_tab.astype('float')\n",
    "# test_tab.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(30, 30))\n",
    "# sns.heatmap(test_tab.corr(), annot=True, cmap='RdYlBu_r', vmin=-1, vmax=1)\n",
    "# plt.savefig(\"heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates = dataset['announced_on'].dt.strftime('%Y-%m-%d')\n",
    "# dates = dates.str[:4]\n",
    "# dates = dates.values.astype(int)\n",
    "# dates = dates.ravel()\n",
    "# dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# pair_ids = list(itertools.combinations(range(len(test_tab.columns)), 2))\n",
    "# for pair in pair_ids:\n",
    "#     plt.figure(figsize=(10, 10))\n",
    "#     plt.scatter(test_tab.iloc[:, pair[0]], test_tab.iloc[:, pair[1]], c=dates, cmap='RdYlBu_r')\n",
    "#     plt.xlabel(test_tab.iloc[:, pair[0]].name)\n",
    "#     plt.ylabel(test_tab.iloc[:, pair[1]].name)\n",
    "#     plt.grid()\n",
    "#     plt.savefig(\"Plots/\" + test_tab.iloc[:, pair[0]].name + \" VS \" + test_tab.iloc[:, pair[1]].name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes = dataset.copy()\n",
    "# classes.loc[classes['class'] == 'narwhal', 'class'] = 0\n",
    "# classes.loc[classes['class'] == 'rhino', 'class'] = 1\n",
    "# classes = classes['class'].values\n",
    "# classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# scatter = plt.scatter(dataset['time_from_previous'], dataset['log_delta'], c=classes, cmap='RdYlBu_r')\n",
    "# plt.xlabel('time_from_previous')\n",
    "# plt.ylabel('log_delta')\n",
    "# plt.grid()\n",
    "# plt.legend(handles=scatter.legend_elements()[0], labels=['narwhal', 'rhino'])\n",
    "# plt.savefig(\"pre_exit_time_from_previous VS log_delta.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# scatter = plt.scatter(exits['time_from_previous'], exits['log_delta'], c=classes, cmap='RdYlBu_r')\n",
    "# plt.xlabel('time_from_previous')\n",
    "# plt.ylabel('log_delta')\n",
    "# plt.grid()\n",
    "# plt.legend(handles=scatter.legend_elements()[0], labels=['narwhal', 'rhino'])\n",
    "# plt.savefig(\"exit_time_from_previous VS log_delta.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[['not_dead']] # 'class' 'exit_type'\n",
    "X = dataset.drop(columns=['not_dead', 'exit_type', 'funding_round_uuid', 'company_name', 'company_uuid', 'investment_type', 'announced_on', 'raised_amount_usd', 'post_money_valuation_usd', 'exit_date', 'price_usd', 'money_raised_usd', 'total_count', 'count_per_round', 'exp_months_std', 'interpolated_money_valuation_usd', 'total_sum_raised', 'lnP', 'log_delta', 'top_investor', 'other_investor'])\n",
    "\n",
    "X = X[['valuation',\n",
    "        'total_sum_raised_before',\n",
    "#        'time_from_2009',\n",
    "        'val_rate',\n",
    "        'time_from_previous',\n",
    "        'time_from_start',\n",
    "#         'from_top5_count',\n",
    "#         'PHD_count',\n",
    "#         'Master_count',\n",
    "#         'MBA_count',\n",
    "#         'exp_months_min',\n",
    "#         'exp_months_max',\n",
    "#         'exp_months_mean',\n",
    "        'top_investor_rounds',\n",
    "        'other_investor_rounds'\n",
    "        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_send = X.copy()\n",
    "# X_send.columns = ['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12', 'col13', 'col14']\n",
    "# X_send.to_csv('X_send_w1.csv', encoding = 'utf-8-sig')\n",
    "# X_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_send = y.copy()\n",
    "# y_send.columns = ['answer']\n",
    "# y_send.to_csv('y_send_w1.csv', encoding = 'utf-8-sig')\n",
    "# y_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['valuation', 'total_sum_raised_before', 'val_rate',\n",
       "       'time_from_previous', 'time_from_start', 'top_investor_rounds',\n",
       "       'other_investor_rounds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X.columns\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554, 7)\n"
     ]
    }
   ],
   "source": [
    "X = X.values.astype(np.float) #X = X.to_numpy(dtype=np.float)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(554,)\n"
     ]
    }
   ],
   "source": [
    "y = y.values.ravel() #y = y.to_numpy()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "skaler = StandardScaler()\n",
    "X_train_t = skaler.fit_transform(X_train)\n",
    "X_test_t = skaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "selector = SelectKBest(f_classif, k='all')\n",
    "selector.fit(X_train_t, y_train)\n",
    "\n",
    "#самый большой результат соответствует самому малому значению p-значения(вероятность ошибки)\n",
    "#поэтому \"переворачиваем\", чтоб самые ценные признаки на графике были максимальными\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "plt.bar(range(len(features)), scores)\n",
    "plt.xticks(range(len(features)), features, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave1_acc = []\n",
    "wave1_PR = []\n",
    "wave1_RC = []\n",
    "wave1_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 50,\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 110}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid1 = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [None, 25, 50, 75, 100],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]\n",
    "}\n",
    "\n",
    "estimator1 = RandomForestClassifier()\n",
    "grid_search1 = GridSearchCV(estimator = estimator1, param_grid = param_grid1, cv = 5, n_jobs = -1, verbose = 2, scoring='accuracy')\n",
    "grid_search1.fit(X_train_t, y_train)\n",
    "grid_search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.5693693693693694\n",
      "PR = 0.5667387687995659\n",
      "RC = 0.5661668839634941\n",
      "f1 = 0.5660082147965614\n"
     ]
    }
   ],
   "source": [
    "acc_array = []\n",
    "PR_array = []\n",
    "RC_array = []\n",
    "f1_array = []\n",
    "feature_array = []\n",
    "best_grid1 = grid_search1.best_estimator_\n",
    "for j in range(10):\n",
    "    best_grid1.fit(X_train_t, y_train)\n",
    "    predicted_labels = best_grid1.predict(X_test_t)\n",
    "    acc = accuracy_score(y_test, predicted_labels)\n",
    "    f1 = f1_score(y_test, predicted_labels, average = 'macro')\n",
    "    PR = precision_score(y_test, predicted_labels, average = 'macro')\n",
    "    RC = recall_score(y_test, predicted_labels, average = 'macro')\n",
    "    acc_array.append(acc)\n",
    "    PR_array.append(PR)\n",
    "    RC_array.append(RC)\n",
    "    f1_array.append(f1)\n",
    "    feature_array.append(best_grid1.feature_importances_)\n",
    "print(f'acc = {np.mean(acc_array)}')\n",
    "print(f'PR = {np.mean(PR_array)}')\n",
    "print(f'RC = {np.mean(RC_array)}')\n",
    "print(f'f1 = {np.mean(f1_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(features)), best_grid1.feature_importances_)\n",
    "plt.xticks(range(len(features)), features, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave1_acc.append(np.mean(acc_array))\n",
    "wave1_PR.append(np.mean(PR_array))\n",
    "wave1_RC.append(np.mean(RC_array))\n",
    "wave1_features.append(np.average(feature_array, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1440 candidates, totalling 7200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3,\n",
       " 'max_depth': 75,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 60}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid2 = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'max_depth': [None, 25, 50, 75, 100],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [20, 50, 60, 70, 80, 90, 100, 110]\n",
    "}\n",
    "\n",
    "estimator2 = GradientBoostingClassifier()\n",
    "grid_search2 = GridSearchCV(estimator = estimator2, param_grid = param_grid2, cv = 5, n_jobs = -1, verbose = 2, scoring='accuracy')\n",
    "grid_search2.fit(X_train_t, y_train)\n",
    "grid_search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.5666666666666667\n",
      "PR = 0.5639572879313081\n",
      "RC = 0.563168187744459\n",
      "f1 = 0.5628633417157494\n"
     ]
    }
   ],
   "source": [
    "acc_array = []\n",
    "f1_array = []\n",
    "PR_array = []\n",
    "RC_array = []\n",
    "feature_array = []\n",
    "best_grid2 = grid_search2.best_estimator_\n",
    "for j in range(10):\n",
    "    best_grid2.fit(X_train_t, y_train)\n",
    "    predicted_labels = best_grid2.predict(X_test_t)\n",
    "    acc = accuracy_score(y_test, predicted_labels)\n",
    "    f1 = f1_score(y_test, predicted_labels, average = 'macro')\n",
    "    PR = precision_score(y_test, predicted_labels, average = 'macro')\n",
    "    RC = recall_score(y_test, predicted_labels, average = 'macro')\n",
    "    acc_array.append(acc)\n",
    "    PR_array.append(PR)\n",
    "    RC_array.append(RC)\n",
    "    f1_array.append(f1)\n",
    "    feature_array.append(best_grid2.feature_importances_)\n",
    "print(f'acc = {np.mean(acc_array)}')\n",
    "print(f'PR = {np.mean(PR_array)}')\n",
    "print(f'RC = {np.mean(RC_array)}')\n",
    "print(f'f1 = {np.mean(f1_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(features)), best_grid2.feature_importances_)\n",
    "plt.xticks(range(len(features)), features, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave1_acc.append(np.mean(acc_array))\n",
    "wave1_PR.append(np.mean(PR_array))\n",
    "wave1_RC.append(np.mean(RC_array))\n",
    "wave1_features.append(np.average(feature_array, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:21:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barca\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5,\n",
       " 'gamma': 0.25,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 7,\n",
       " 'reg_lambda': 1,\n",
       " 'scale_pos_weight': 1,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "}\n",
    "\n",
    "estimator = XGBClassifier(objective=\"binary:logistic\")\n",
    "grid_search = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=3, scoring=\"accuracy\") #verbose = 2, scoring='accuracy' roc_auc\n",
    "grid_search.fit(X_train_t, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.657014157014157"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:21:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=0.25, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=7,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=0.8,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best_grid = grid_search.best_estimator_\n",
    "best_grid = XGBClassifier(objective=\"binary:logistic\", **grid_search.best_params_)\n",
    "best_grid.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc = 0.5315315315315315\n",
      "PR = 0.5269230769230769\n",
      "RC = 0.526238591916558\n",
      "f1 = 0.5250164581961818\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = best_grid.predict(X_test_t)\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, predicted_labels)\n",
    "acc = accuracy_score(y_test, predicted_labels)\n",
    "f1 = f1_score(y_test, predicted_labels, average = 'macro')\n",
    "PR = precision_score(y_test, predicted_labels, average = 'macro')\n",
    "RC = recall_score(y_test, predicted_labels, average = 'macro')\n",
    "\n",
    "print(f'acc = {acc}')\n",
    "print(f'PR = {PR}')\n",
    "print(f'RC = {RC}')\n",
    "print(f'f1 = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(len(features)), best_grid.feature_importances_)\n",
    "plt.xticks(range(len(features)), features, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave1_acc.append(acc)\n",
    "wave1_PR.append(PR)\n",
    "wave1_RC.append(RC)\n",
    "wave1_features.append(best_grid.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5693693693693694, 0.5666666666666667, 0.5315315315315315]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave1_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5667387687995659, 0.5639572879313081, 0.5269230769230769]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave1_PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5661668839634941, 0.563168187744459, 0.526238591916558]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave1_RC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.16748497, 0.23114568, 0.15117494, 0.14974764, 0.14026995,\n",
       "        0.10731756, 0.05285927]),\n",
       " array([0.16715027, 0.28564779, 0.12479347, 0.15967584, 0.13926536,\n",
       "        0.0747409 , 0.04872638]),\n",
       " array([0.16548713, 0.19838908, 0.11711226, 0.11997741, 0.11898546,\n",
       "        0.18906835, 0.09098036], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>Gradient Boosting</th>\n",
       "      <th>XGBoost Classifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACCURACY</td>\n",
       "      <td>0.589189</td>\n",
       "      <td>0.564865</td>\n",
       "      <td>0.531532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>valuation</td>\n",
       "      <td>0.168863</td>\n",
       "      <td>0.169654</td>\n",
       "      <td>0.165487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_sum_raised_before</td>\n",
       "      <td>0.237873</td>\n",
       "      <td>0.281469</td>\n",
       "      <td>0.198389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val_rate</td>\n",
       "      <td>0.156993</td>\n",
       "      <td>0.126378</td>\n",
       "      <td>0.117112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>time_from_previous</td>\n",
       "      <td>0.144367</td>\n",
       "      <td>0.163538</td>\n",
       "      <td>0.119977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>time_from_start</td>\n",
       "      <td>0.133478</td>\n",
       "      <td>0.135490</td>\n",
       "      <td>0.118985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>top_investor_rounds</td>\n",
       "      <td>0.111198</td>\n",
       "      <td>0.075222</td>\n",
       "      <td>0.189068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>other_investor_rounds</td>\n",
       "      <td>0.047229</td>\n",
       "      <td>0.048249</td>\n",
       "      <td>0.090980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Parameter  Random Forest  Gradient Boosting  \\\n",
       "0                 ACCURACY       0.589189           0.564865   \n",
       "1                valuation       0.168863           0.169654   \n",
       "2  total_sum_raised_before       0.237873           0.281469   \n",
       "3                 val_rate       0.156993           0.126378   \n",
       "4       time_from_previous       0.144367           0.163538   \n",
       "5          time_from_start       0.133478           0.135490   \n",
       "6      top_investor_rounds       0.111198           0.075222   \n",
       "7    other_investor_rounds       0.047229           0.048249   \n",
       "\n",
       "   XGBoost Classifier  \n",
       "0            0.531532  \n",
       "1            0.165487  \n",
       "2            0.198389  \n",
       "3            0.117112  \n",
       "4            0.119977  \n",
       "5            0.118985  \n",
       "6            0.189068  \n",
       "7            0.090980  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wave1real_df = pd.DataFrame(list(zip([wave1_acc[0]], [wave1_acc[1]], [wave1_acc[2]])), \n",
    "               columns =['Random Forest', 'Gradient Boosting', 'XGBoost Classifier'])\n",
    "wave1realf_df = pd.DataFrame(list(zip(wave1_features[0], wave1_features[1], wave1_features[2])), \n",
    "               columns =['Random Forest', 'Gradient Boosting', 'XGBoost Classifier'])\n",
    "features = features.insert(0, 'ACCURACY')\n",
    "parameters = pd.DataFrame(list(features), columns =['Parameter'])\n",
    "wave1real_df = wave1real_df.append(wave1realf_df).reset_index(drop=True)\n",
    "wave1real_df = pd.concat([parameters, wave1real_df], axis=1)\n",
    "wave1real_df.to_csv('wave1_results.csv', encoding = 'utf-8-sig')\n",
    "wave1real_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### На единичных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time_from_2009', 'time_from_start', 'time_from_previous',\n",
       "       'top_investor_count', 'other_investor_count', 'top_investor_sum',\n",
       "       'other_investor_sum', 'top_investor_rounds', 'other_investor_rounds',\n",
       "       'top_quantil', 'is_PHD', 'is_Master', 'is_MBA', 'exp_months_min',\n",
       "       'exp_months_max', 'exp_months_mean', 'total_sum_raised_before',\n",
       "       'valuation', 'log_rate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset[['not_dead']]\n",
    "y = y.values.ravel()\n",
    "X_general = dataset.drop(columns=['class', 'not_dead', 'exit_type', 'funding_round_uuid', 'company_name', 'company_uuid', 'investment_type', 'announced_on', 'raised_amount_usd', 'post_money_valuation_usd', 'exit_date', 'price_usd', 'money_raised_usd', 'total_count', 'count_per_round', 'exp_months_std', 'interpolated_money_valuation_usd', 'total_sum_raised', 'lnP', 'log_delta', 'top_investor', 'other_investor'])\n",
    "\n",
    "skaler = StandardScaler()\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False], #rf only\n",
    "#    'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], #boosting only\n",
    "    'max_depth': [None, 25, 50, 75, 100],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110]\n",
    "}\n",
    "estimator = RandomForestClassifier() #0.65-0.71\n",
    "#estimator = GradientBoostingClassifier() #0.6-0.66\n",
    "grid_search = GridSearchCV(estimator = estimator, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2, scoring='accuracy')\n",
    "\n",
    "X_general.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done 1028 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2160 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3620 tasks      | elapsed:   31.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   41.0s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   17.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   32.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   40.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   24.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   31.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   39.4s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   28.1s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   28.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.4s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   33.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.4s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   27.9s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   37.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   32.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   40.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   32.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   40.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   31.2s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   38.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   16.1s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   37.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 990 candidates, totalling 4950 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 658 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1224 tasks      | elapsed:   10.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1954 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2844 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=-1)]: Done 3898 tasks      | elapsed:   32.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Accuracy   F-Score\n",
      "time_from_2009           0.648649  0.647619\n",
      "time_from_start          0.480180  0.463604\n",
      "time_from_previous       0.466667  0.466340\n",
      "top_investor_count       0.634234  0.632031\n",
      "other_investor_count     0.495495  0.474203\n",
      "top_investor_sum         0.506306  0.505711\n",
      "other_investor_sum       0.518919  0.515798\n",
      "top_investor_rounds      0.598198  0.556082\n",
      "other_investor_rounds    0.459459  0.455882\n",
      "top_quantil              0.548649  0.524318\n",
      "is_PHD                   0.574775  0.568179\n",
      "is_Master                0.526126  0.526111\n",
      "is_MBA                   0.613514  0.610001\n",
      "exp_months_min           0.567568  0.565841\n",
      "exp_months_max           0.518919  0.513704\n",
      "exp_months_mean          0.500901  0.499190\n",
      "total_sum_raised_before  0.581081  0.569306\n",
      "valuation                0.548649  0.547730\n",
      "log_rate                 0.541441  0.531766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 4950 out of 4950 | elapsed:   40.4s finished\n"
     ]
    }
   ],
   "source": [
    "mean_acc = []\n",
    "mean_f1 = []\n",
    "features = ['time_from_2009', 'time_from_start', 'time_from_previous',\n",
    "       'top_investor_count', 'other_investor_count', 'top_investor_sum',\n",
    "       'other_investor_sum', 'top_investor_rounds', 'other_investor_rounds',\n",
    "       'from_top5_count', 'PHD_count', 'Master_count', 'MBA_count', 'exp_months_min',\n",
    "       'exp_months_max', 'exp_months_mean', 'total_sum_raised_before',\n",
    "       'valuation', 'val_rate']\n",
    "for i in features:\n",
    "    X = X_general[[i]]\n",
    "    X = X.values.astype(np.float)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    X_train_t = skaler.fit_transform(X_train)\n",
    "    X_test_t = skaler.transform(X_test)\n",
    "    grid_search.fit(X_train_t, y_train)\n",
    "    best_grid = grid_search.best_estimator_\n",
    "    \n",
    "    acc_array = []\n",
    "    f1_array = []\n",
    "    PR_array = []\n",
    "    RC_array = []\n",
    "    for j in range(10):\n",
    "        best_grid.fit(X_train_t, y_train)\n",
    "        predicted_labels = best_grid.predict(X_test_t)\n",
    "        acc = accuracy_score(y_test, predicted_labels)\n",
    "        f1 = f1_score(y_test, predicted_labels, average = 'macro')\n",
    "        PR = precision_score(y_test, predicted_labels, average = 'macro')\n",
    "        RC = recall_score(y_test, predicted_labels, average = 'macro')\n",
    "        acc_array.append(acc)\n",
    "        PR_array.append(PR)\n",
    "        RC_array.append(RC)\n",
    "        f1_array.append(f1)\n",
    "    mean_acc.append(np.mean(acc_array))\n",
    "    mean_f1.append(np.mean(f1_array))\n",
    "    #print(f'acc on {i} = {np.mean(acc_array)}')\n",
    "    #print(f'f1 on {i} = {np.mean(f1_array)}')\n",
    "mean_acc_f1_df = pd.DataFrame(list(zip(mean_acc, mean_f1)), \n",
    "               columns =['Accuracy', 'F-Score']).set_index([features])\n",
    "print(mean_acc_f1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>time_from_2009</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.647619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_from_start</th>\n",
       "      <td>0.480180</td>\n",
       "      <td>0.463604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_from_previous</th>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_investor_count</th>\n",
       "      <td>0.634234</td>\n",
       "      <td>0.632031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_investor_count</th>\n",
       "      <td>0.495495</td>\n",
       "      <td>0.474203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_investor_sum</th>\n",
       "      <td>0.506306</td>\n",
       "      <td>0.505711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_investor_sum</th>\n",
       "      <td>0.518919</td>\n",
       "      <td>0.515798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_investor_rounds</th>\n",
       "      <td>0.598198</td>\n",
       "      <td>0.556082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other_investor_rounds</th>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.455882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top_quantil</th>\n",
       "      <td>0.548649</td>\n",
       "      <td>0.524318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_PHD</th>\n",
       "      <td>0.574775</td>\n",
       "      <td>0.568179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_Master</th>\n",
       "      <td>0.526126</td>\n",
       "      <td>0.526111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_MBA</th>\n",
       "      <td>0.613514</td>\n",
       "      <td>0.610001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_months_min</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.565841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_months_max</th>\n",
       "      <td>0.518919</td>\n",
       "      <td>0.513704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exp_months_mean</th>\n",
       "      <td>0.500901</td>\n",
       "      <td>0.499190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_sum_raised_before</th>\n",
       "      <td>0.581081</td>\n",
       "      <td>0.569306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valuation</th>\n",
       "      <td>0.548649</td>\n",
       "      <td>0.547730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_rate</th>\n",
       "      <td>0.541441</td>\n",
       "      <td>0.531766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy   F-Score\n",
       "time_from_2009           0.648649  0.647619\n",
       "time_from_start          0.480180  0.463604\n",
       "time_from_previous       0.466667  0.466340\n",
       "top_investor_count       0.634234  0.632031\n",
       "other_investor_count     0.495495  0.474203\n",
       "top_investor_sum         0.506306  0.505711\n",
       "other_investor_sum       0.518919  0.515798\n",
       "top_investor_rounds      0.598198  0.556082\n",
       "other_investor_rounds    0.459459  0.455882\n",
       "top_quantil              0.548649  0.524318\n",
       "is_PHD                   0.574775  0.568179\n",
       "is_Master                0.526126  0.526111\n",
       "is_MBA                   0.613514  0.610001\n",
       "exp_months_min           0.567568  0.565841\n",
       "exp_months_max           0.518919  0.513704\n",
       "exp_months_mean          0.500901  0.499190\n",
       "total_sum_raised_before  0.581081  0.569306\n",
       "valuation                0.548649  0.547730\n",
       "log_rate                 0.541441  0.531766"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_acc_f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# acc_train = []\n",
    "# acc_test = []\n",
    "# f1_train = []\n",
    "# f1_test = []\n",
    "# for i in range(1, 101):\n",
    "#     #classifier = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=100, C=0.12, penalty='l1', n_jobs=-1) #меньше 0.6\n",
    "#     #classifier = KNeighborsClassifier(n_neighbors=20, weights='distance', n_jobs =-1) #отвратительное качество\n",
    "#     classifier = DecisionTreeClassifier(max_depth=100) #качество на уровне 0.65-0.7\n",
    "    \n",
    "#     #ensemble_classifier = BaggingClassifier(base_estimator=classifier, n_estimators=i, bootstrap=True, n_jobs=-1)\n",
    "#     ensemble_classifier = RandomForestClassifier(n_estimators=i, n_jobs=-1) #качество на уровне 0.65-0.7\n",
    "#     #ensemble_classifier = GradientBoostingClassifier(n_estimators=i, learning_rate=0.2, max_depth=10) #качество на уровне 0.6-0.7\n",
    "    \n",
    "#     ensemble_classifier.fit(X_train_t, y_train)\n",
    "#     class_names = ensemble_classifier.classes_\n",
    "#     y_train_b = label_binarize(y_train, class_names)\n",
    "#     y_test_b = label_binarize(y_test, class_names)\n",
    "#     y_predict_train_b = label_binarize(ensemble_classifier.predict(X_train_t), class_names)\n",
    "#     y_predict_test_b = label_binarize(ensemble_classifier.predict(X_test_t), class_names)\n",
    "#     acc_train.append(accuracy_score(y_train_b, y_predict_train_b))\n",
    "#     f1_train.append(f1_score(y_train_b, y_predict_train_b, average='weighted'))\n",
    "#     acc_test.append(accuracy_score(y_test_b, y_predict_test_b))\n",
    "#     f1_test.append(f1_score(y_test_b, y_predict_test_b, average='weighted'))\n",
    "\n",
    "# plt.figure(figsize=(7, 7))\n",
    "# plt.plot(np.arange(1, 101), acc_train, label='accuracy train')\n",
    "# plt.plot(np.arange(1, 101), f1_train, label='f1_score train')\n",
    "# plt.plot(np.arange(1, 101), acc_test, label='accuracy test')\n",
    "# plt.plot(np.arange(1, 101), f1_test, label='f1_score test')\n",
    "# plt.xlabel('n_estimators')\n",
    "# plt.ylabel('score')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogReg, kNN, Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg = {'C': np.linspace(0.01, 1, 10), 'penalty': ['l1', 'l2']}\n",
    "#pg = {'n_neighbors': range(1, 21)}\n",
    "#pg = {'max_depth': np.linspace(1, 100, 5)}\n",
    "\n",
    "#classifier = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=1000, n_jobs =-1) #lbfgs\n",
    "#classifier = KNeighborsClassifier(weights='distance')\n",
    "#classifier = DecisionTreeClassifier()\n",
    "\n",
    "#grid_search = GridSearchCV(estimator=classifier, n_jobs = -1, param_grid=pg, cv=5, scoring='accuracy')\n",
    "#grid_search.fit(X_train_t, y_train)\n",
    "\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_classifier = grid_search.best_estimator_\n",
    "#best_classifier.fit(X_train_t, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_labels = best_classifier.predict(X_test_t)\n",
    "\n",
    "#acc = accuracy_score(y_test, predicted_labels)\n",
    "#print(f'acc = {acc}')\n",
    "#f1 = f1_score(y_test, predicted_labels, average = 'macro')\n",
    "#print(f'f1 = {f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_proba = grid_search.predict_proba(X_test_t)\n",
    "#for i in predict_proba:\n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_names = grid_search.best_estimator_.classes_\n",
    "#y_predict = grid_search.predict_proba(X_test_t)\n",
    "\n",
    "##y_test_b = label_binarize(y_test, class_names)\n",
    "#lb = LabelBinarizer()\n",
    "#y_test_b = lb.fit_transform(y_test)\n",
    "#y_test_b = np.hstack((1 - y_test_b, y_test_b))\n",
    "\n",
    "#fpr = dict()\n",
    "#tpr = dict()\n",
    "#roc_auc = dict()\n",
    "#for i in range(len(class_names)):\n",
    "#    fpr[i], tpr[i], _ = roc_curve(y_test_b[:, i], y_predict[:, i])\n",
    "#    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "##для микро\n",
    "#fpr['micro'], tpr['micro'], _ = roc_curve(y_test_b.ravel(), y_predict.ravel())\n",
    "#roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])\n",
    "\n",
    "##макро\n",
    "#all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(class_names))]))\n",
    "#mean_tpr = np.zeros_like(all_fpr)\n",
    "#for i in range(len(class_names)):\n",
    "#    mean_tpr += interp(all_fpr, fpr[i], tpr[i]) \n",
    "#mean_tpr /= len(class_names)\n",
    "#fpr['macro'] = all_fpr\n",
    "#tpr['macro'] = mean_tpr\n",
    "#roc_auc['macro'] = auc(fpr['macro'], tpr['macro'])\n",
    "\n",
    "##графики\n",
    "#plt.figure(figsize=(6,6))\n",
    "#plt.plot(fpr['micro'], tpr['micro'], label='micro, auc = %.3f'%(roc_auc['micro']), linestyle='--')\n",
    "#plt.plot(fpr['macro'], tpr['macro'], label='macro, auc = %.3f'%(roc_auc['macro']), linestyle='--')\n",
    "#for i in range(len(class_names)):\n",
    "#    plt.plot(fpr[i], tpr[i], label='class = %s, auc = %.3f'%(class_names[i], auc(fpr[i], tpr[i])))\n",
    "\n",
    "#plt.title('ROC-Кривая')\n",
    "#plt.xlabel('False Positive Rate')\n",
    "#plt.ylabel('True Positive Rate')\n",
    "#plt.legend()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сокращение размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA()\n",
    "#pca.fit(X_train_t)\n",
    "\n",
    "#variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "#plt.figure(figsize=(5,5))\n",
    "#plt.plot(variance)\n",
    "#plt.xlabel('Components')\n",
    "#plt.ylabel('EVR')\n",
    "#plt.plot([0,46],[0.95,0.95])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=39)\n",
    "\n",
    "#X_train_pca = pca.fit_transform(X_train_t)\n",
    "#X_test_pca = pca.transform(X_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pg = {'C': np.linspace(0.01, 1, 10), 'penalty': ['l1', 'l2']}\n",
    "#pg = {'n_neighbors': range(1, 31)}\n",
    "#pg = {'max_depth': np.linspace(1, 100, 5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = LogisticRegression(solver='saga', multi_class='multinomial', max_iter=100, n_jobs =-1) #lbfgs\n",
    "#classifier = KNeighborsClassifier(weights='distance')\n",
    "#classifier = DecisionTreeClassifier()\n",
    "\n",
    "#grid_search = GridSearchCV(estimator=classifier, n_jobs = -1, param_grid=pg, cv=5, scoring='accuracy')\n",
    "#grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_labels = grid_search.predict(X_test_pca)\n",
    "\n",
    "#acc = accuracy_score(y_test, predicted_labels)\n",
    "#f1 = f1_score(y_test, predicted_labels, average='weighted')\n",
    "#print('acc = ', acc)\n",
    "#print('f1 = ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset[['not_dead']] #'not_dead' 'exit_type' 'class'\n",
    "X = dataset.drop(columns=['class', 'not_dead', 'exit_type', 'top_investor', 'other_investor', 'total_sum_raised', 'first_last_dif', 'stadia', 'investment_type', 'log_delta', 'price_usd', 'money_raised_usd', 'exp_months_std', 'funding_round_uuid', 'company_name', 'company_uuid', 'announced_on', 'exit_date', 'total_count', 'count_per_round', 'raised_amount_usd', 'post_money_valuation_usd', 'interpolated_money_valuation_usd', 'lnP'])\n",
    "\n",
    "#только признаки команды (образование + опыт)\n",
    "#X = X.drop(columns=['time_from_2009', 'time_from_previous', 'time_from_start', 'top_investor_sum', 'other_investor_sum', 'total_sum_raised_before', 'valuation', 'val_rate'])\n",
    "\n",
    "#только инвестора и раунды\n",
    "X = X[['valuation', 'val_rate', 'total_sum_raised_before', 'time_from_2009', 'time_from_previous', 'time_from_start', 'top_investor_sum', 'other_investor_sum']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "skaler = StandardScaler()\n",
    "X_train_t = skaler.fit_transform(X_train)\n",
    "X_eval_t = skaler.fit_transform(X_eval)\n",
    "X_test_t = skaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6514671\ttest: 0.6741755\tbest: 0.6741755 (0)\ttotal: 155ms\tremaining: 2m 34s\n",
      "100:\tlearn: 0.0489779\ttest: 0.6215706\tbest: 0.5913487 (16)\ttotal: 1.58s\tremaining: 14.1s\n",
      "200:\tlearn: 0.0177040\ttest: 0.6744059\tbest: 0.5913487 (16)\ttotal: 2.9s\tremaining: 11.6s\n",
      "300:\tlearn: 0.0101371\ttest: 0.7124593\tbest: 0.5913487 (16)\ttotal: 4.2s\tremaining: 9.76s\n",
      "400:\tlearn: 0.0069237\ttest: 0.7399347\tbest: 0.5913487 (16)\ttotal: 5.55s\tremaining: 8.29s\n",
      "500:\tlearn: 0.0053840\ttest: 0.7578491\tbest: 0.5913487 (16)\ttotal: 6.87s\tremaining: 6.84s\n",
      "600:\tlearn: 0.0044076\ttest: 0.7763442\tbest: 0.5913487 (16)\ttotal: 8.21s\tremaining: 5.45s\n",
      "700:\tlearn: 0.0038291\ttest: 0.7896251\tbest: 0.5913487 (16)\ttotal: 9.62s\tremaining: 4.1s\n",
      "800:\tlearn: 0.0033698\ttest: 0.7988073\tbest: 0.5913487 (16)\ttotal: 10.9s\tremaining: 2.72s\n",
      "900:\tlearn: 0.0030590\ttest: 0.8067507\tbest: 0.5913487 (16)\ttotal: 12.3s\tremaining: 1.35s\n",
      "999:\tlearn: 0.0028825\ttest: 0.8127623\tbest: 0.5913487 (16)\ttotal: 13.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.5913486676\n",
      "bestIteration = 16\n",
      "\n",
      "Shrink model to first 17 iterations.\n",
      "CatBoost: prediction of not_dead: RMSLE on test = 0.8127623261614878\n"
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(has_time=True, iterations=1000, depth=10, learning_rate=0.1, loss_function='CrossEntropy')\n",
    "model.fit(X_train_t, y_train, eval_set=(X_eval_t, y_eval), verbose=100)\n",
    "\n",
    "print ('CatBoost: prediction of %s: RMSLE on test = %s' % ('not_dead', model.evals_result_['validation']['CrossEntropy'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_t)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test.values.ravel()\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CatBoost: prediction of log_delta. Feature importance. Type=PredictionValuesChange\n",
      "  Feature Id  Importances\n",
      "0          6    19.197516\n",
      "1          3    18.696240\n",
      "2          0    17.847655\n",
      "3          7    12.064020\n",
      "4          2     9.962412\n",
      "5          4     8.120351\n",
      "6          5     7.730078\n",
      "7          1     6.381729\n"
     ]
    }
   ],
   "source": [
    "print ('\\nCatBoost: prediction of %s. Feature importance. Type=PredictionValuesChange' % 'log_delta')\n",
    "print (model.get_feature_importance(type=cb.EFstrType.PredictionValuesChange, prettified=True).head(25).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6564885496183206"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test_t, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
